{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup required for all notebooks & data preparation for VTT files\n",
    "---------------------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "**This step of our solution design covers running setup steps that need to be run prior to any other notebook being run.**\n",
    "\n",
    "1. Prerequisite: a `Python 3.11` conda environment with the packages in `requirements.txt` installed.\n",
    "\n",
    "1. In this notebook, we chapterize meeting transcripts given in the form of `VTT` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from chapterize import chapterize\n",
    "from IPython.display import display, HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a logger to log all messages while the code runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## load the config file\n",
    "CONFIG_FILE_PATH = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vtt_data(vtt_file: str, max_chapter_length: int, header_lines_to_skip: int = 2, num_lines_per_message: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function processes the VTT files provided, scans each file and converts it into a data frame with content on the file name, chapter id, \n",
    "    speaker_if, text, and other variables required in the data frame to get model generated titles in the next notebook.\n",
    "    \"\"\"\n",
    "    logger.info(f\"vtt_file=\\\"{vtt_file}\\\", max_chapter_length={max_chapter_length}, header_lines_to_skip={header_lines_to_skip}\")\n",
    "    desired_lines = []\n",
    "    with open(vtt_file) as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        desired_lines = lines[header_lines_to_skip:]\n",
    "    desired_lines = list(filter(None, desired_lines))\n",
    "    file_name = os.path.basename(vtt_file)\n",
    "    array_of_dicts = []\n",
    "    chapter_count = 1\n",
    "    for n in range(len(desired_lines) // num_lines_per_message):\n",
    "        l1 = desired_lines[n * num_lines_per_message].split('\"')\n",
    "        name = f'\"{l1[1]}\"'\n",
    "        speaker_id = l1[2].strip().strip('()')\n",
    "        l2 = desired_lines[n * num_lines_per_message + 1].split(' --> ')\n",
    "        start_time = l2[0]\n",
    "        end_time = l2[1].strip()\n",
    "        text = f'\"{desired_lines[n * num_lines_per_message + (num_lines_per_message-1)]}\"'\n",
    "        new_row = {'file_name': file_name,\n",
    "                   'chapter_id': chapter_count,\n",
    "                   'name': name,\n",
    "                   'speaker_id': speaker_id,\n",
    "                   'start_time': start_time,\n",
    "                   'end_time': end_time,\n",
    "                   'text': text,}\n",
    "        array_of_dicts.append(new_row)\n",
    "        if (n + 1) % max_chapter_length == 0:\n",
    "            chapter_count += 1\n",
    "    df = pd.DataFrame(array_of_dicts)\n",
    "    logger.info(f\"Converted {vtt_file} into dataframe of shape={df.shape} after processing vtt file=\\\"{file_name}\\\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run this cell, ensure that the `file_type_to_process` in the `dir` section of the config file is set to `vtt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over files in that directory\n",
    " \n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(config['dir']['processed'], exist_ok=True)\n",
    "\n",
    "df_list: List[pd.DataFrame] = []\n",
    "raw_files = glob.glob(os.path.join(config['dir']['raw'], f\"*.{config['dir']['file_type_to_process']}\"))\n",
    "logger.info(f\"there are {len(raw_files)} files to be processed \")\n",
    "df_list = list(map(lambda f: process_vtt_data(f, config['title_generation_thresholds']['max_chapter_length']), raw_files))\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "fpath: str = os.path.join(config['dir']['processed'], config['dir']['processed_file'])\n",
    "df.to_csv(fpath, encoding='utf-8', header='true', index=False)\n",
    "logger.info(df.head())\n",
    "logger.info(f\"Final processed dataframe of shape={df.shape} written to \\\"{fpath}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chapterize(df)\n",
    "fpath: str = os.path.join(config['dir']['processed'], config['dir']['chapterized_file'])\n",
    "df.to_csv(fpath, encoding='utf-8', header='true', index=False)\n",
    "logger.info(df.head())\n",
    "logger.info(f\"Final processed dataframe of shape={df.shape} written to \\\"{fpath}\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
