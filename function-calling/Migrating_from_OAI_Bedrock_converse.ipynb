{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrating OpenAI Function calling (Tool Use) to Converse API Function Calling with Amazon Bedrock Converse API\n",
    "\n",
    "In this example notebook, we'll explore how to migrate OpenAI Function calling to work with function calling provided by the Converse API for Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensure you have at least version 1.34.117 of boto3\n",
    "# !pip3 install -qU boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running boto3 version: 1.34.117\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from typing import Dict, List \n",
    "import pprint \n",
    "\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a few variables. Make sure to adjust these parameters according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define a set of Bedrock models we'll test with Function Calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_IDS = [\n",
    "    'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "    'mistral.mistral-large-2402-v1:0',\n",
    "    'cohere.command-r-plus-v1:0',\n",
    "    'cohere.command-r-v1:0'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up our boto3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "region = 'us-east-1'\n",
    "print('Using region: ', region)\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name = 'bedrock-runtime',\n",
    "    region_name = region,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a utility function to migrate an existing OpenAI function call to a Bedrock Converse call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oai_call_to_bedrock_call(oai_call: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Converts an OpenAI function call to a Bedrock Converse call.\n",
    "\n",
    "    Args:\n",
    "        oai_call (Dict): The OAI function call to be converted.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The converted Bedrock Converse call.\n",
    "    \"\"\"\n",
    "    _functions = []\n",
    "\n",
    "    # Each function in OpenAI becomes a \"toolSpec\" for Converse. The OpenAI function\n",
    "    # parameters become a Converse \"inputSchema\".\n",
    "\n",
    "    for _function in oai_call['functions']: \n",
    "        _functions.append({\n",
    "            \"toolSpec\": {\n",
    "                \"name\": _function[\"name\"],\n",
    "                \"description\": _function[\"description\"],\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": _function[\"parameters\"]\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    _messages = []\n",
    "\n",
    "    # Migrate the message \"content\" to have a \"text\" field.\n",
    "\n",
    "    for _message in oai_call['messages']:\n",
    "        _messages.append({\n",
    "            \"role\": _message[\"role\"],\n",
    "            \"content\": [ \n",
    "                {\n",
    "                    \"text\": _message[\"content\"]\n",
    "                }                \n",
    "            ]})\n",
    "    \n",
    "    # Lastly, wrap the tool definitions in a \"toolConfig\" field.\n",
    "\n",
    "    return {\n",
    "        \"messages\": _messages,\n",
    "        \"toolConfig\": {\n",
    "            # Optionally add '\"toolChoice\": {\"auto\": {}},'\n",
    "            \"tools\": _functions\n",
    "        }\n",
    "    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a utility function for exercising Bedrock Converse to have it select the right tool and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse_with_tools(messages: List[Dict], system: str=\"\", toolConfig: Dict={},\n",
    "                        modelId = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                        temperature: float=0.0,\n",
    "                        topP: float=1.0,\n",
    "                        maxTokens: int=512) -> str:\n",
    "    \"\"\"Utility function to call the Bedrock Converse API and get a function calling response from the model.\n",
    "\n",
    "    Args:\n",
    "        messages (List[Dict]): messages to pass to the model\n",
    "        system (str, optional): system prompt\n",
    "        toolConfig (Dict, optional): configuration of tools for the model to choose from\n",
    "        modelId (str, optional): which Bedrock model to use \n",
    "\n",
    "    Returns:\n",
    "        str: response from the model\n",
    "    \"\"\"\n",
    "    system_prompt = [{\"text\": system}]\n",
    "\n",
    "    response = bedrock.converse(\n",
    "        modelId=modelId,\n",
    "        system=system_prompt,\n",
    "        messages=messages,\n",
    "        toolConfig=toolConfig,\n",
    "        inferenceConfig={\n",
    "            'temperature': temperature,\n",
    "            'topP': topP,\n",
    "            'maxTokens': maxTokens\n",
    "            }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a few simle example OpenAI function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_meeting_call = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Schedule a meeting with John Doe next Tuesday at 3 PM.\"\n",
    "    }\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"schedule_meeting\",\n",
    "      \"description\": \"Please schedule a meeting.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"attendee\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Attendee for the meeting\"\n",
    "          },\n",
    "          \"date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Date of the meeting\"\n",
    "          },\n",
    "          \"time\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Time of the meeting\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_stock_call = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What's the current price of Apple stocks?\"\n",
    "    }\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_stock_price\",\n",
    "      \"description\": \"Get current stock price\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"ticker_symbol\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Ticker symbol of the stock\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_travel_call = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I need to book a trip from Bonn to Amsterdam for my wife, mother and by two sons and daughter. I will also be joining them. The airline must fly direct.\"\n",
    "    }\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"book_travel\",\n",
    "      \"description\": \"Book travel\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"destination\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Your travel destination.\"\n",
    "          },\n",
    "          \"departure\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"From where are you traveling\"\n",
    "          },\n",
    "          \"number_people\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"How many people are traveling\"\n",
    "          },\n",
    "          \"travel_mode\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"What mode of travel will it be.\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show a sample converted function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'text': 'Schedule a meeting with John Doe next Tuesday at 3 PM.'}]}],\n",
       " 'toolConfig': {'tools': [{'toolSpec': {'name': 'schedule_meeting',\n",
       "     'description': 'Please schedule a meeting.',\n",
       "     'inputSchema': {'json': {'type': 'object',\n",
       "       'properties': {'attendee': {'type': 'string',\n",
       "         'description': 'Attendee for the meeting'},\n",
       "        'date': {'type': 'string', 'description': 'Date of the meeting'},\n",
       "        'time': {'type': 'string',\n",
       "         'description': 'Time of the meeting'}}}}}}]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_call_to_bedrock_call(open_ai_meeting_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the use of each of these example function calls with Bedrock Converse against a set of Bedrock models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example call: Schedule a meeting with John Doe next Tuesday at 3 PM.\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-sonnet-20240229-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'Here is how to schedule the meeting using '\n",
      "                                  'the available tool:'},\n",
      "                         {'toolUse': {'input': {'attendee': 'John Doe',\n",
      "                                                'date': 'Next Tuesday',\n",
      "                                                'time': '3 PM'},\n",
      "                                      'name': 'schedule_meeting',\n",
      "                                      'toolUseId': 'tooluse_KeFQRzThQTOow-1l4mbpgA'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-haiku-20240307-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'attendee': 'John Doe',\n",
      "                                                'date': 'next Tuesday',\n",
      "                                                'time': '3 PM'},\n",
      "                                      'name': 'schedule_meeting',\n",
      "                                      'toolUseId': 'tooluse_z5IRiGNESW-yhHT1BqOsJQ'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: mistral.mistral-large-2402-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'attendee': 'John Doe',\n",
      "                                                'date': 'next Tuesday',\n",
      "                                                'time': '3 PM'},\n",
      "                                      'name': 'schedule_meeting',\n",
      "                                      'toolUseId': 'tooluse_TBbCJkWgQcOopcn27LKElA'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-plus-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will schedule a meeting with John Doe '\n",
      "                                  'next Tuesday at 3 PM.'},\n",
      "                         {'toolUse': {'input': {'attendee': {'name': 'John '\n",
      "                                                                     'Doe'},\n",
      "                                                'date': {'date': 'Next '\n",
      "                                                                 'Tuesday'},\n",
      "                                                'time': {'time': '3 PM'}},\n",
      "                                      'name': 'schedule_meeting',\n",
      "                                      'toolUseId': 'tooluse_qKuZK7FxQv-b-FZmiF21TQ'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will use the schedule_meeting tool to '\n",
      "                                  'organise a meeting with John Doe next '\n",
      "                                  'Tuesday at 3 PM.'},\n",
      "                         {'toolUse': {'input': {'attendee': {'name': 'John '\n",
      "                                                                     'Doe'},\n",
      "                                                'date': {'weekday': 'Tuesday'},\n",
      "                                                'time': {'hour': 15,\n",
      "                                                         'meridiem': 'PM'}},\n",
      "                                      'name': 'schedule_meeting',\n",
      "                                      'toolUseId': 'tooluse_jGyr242DSWSBiKyXAB6wig'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "Example call: What's the current price of Apple stocks?\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-sonnet-20240229-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'ticker_symbol': 'AAPL'},\n",
      "                                      'name': 'get_stock_price',\n",
      "                                      'toolUseId': 'tooluse_ac31RQDmST6lXzexupk-TA'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-haiku-20240307-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'ticker_symbol': 'AAPL'},\n",
      "                                      'name': 'get_stock_price',\n",
      "                                      'toolUseId': 'tooluse_QvU0H4MkTzC7-6rKCef6ug'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: mistral.mistral-large-2402-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'ticker_symbol': 'AAPL'},\n",
      "                                      'name': 'get_stock_price',\n",
      "                                      'toolUseId': 'tooluse_x40ruHqYTKucoP6d5tBxQA'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-plus-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will use the get_stock_price function to '\n",
      "                                  'find the current price of Apple stocks.'},\n",
      "                         {'toolUse': {'input': {'ticker_symbol': 'AAPL'},\n",
      "                                      'name': 'get_stock_price',\n",
      "                                      'toolUseId': 'tooluse_5lzoOs3eRQOI1NotKtWutg'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will use the function get_stock_price to '\n",
      "                                  'find out the current price of Apple stocks '\n",
      "                                  'and relay this information to the user.'},\n",
      "                         {'toolUse': {'input': {'ticker_symbol': {'symbol': 'AAPL'}},\n",
      "                                      'name': 'get_stock_price',\n",
      "                                      'toolUseId': 'tooluse_O6YydIPEQtaiVwO0BBi0qg'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "Example call: I need to book a trip from Bonn to Amsterdam for my wife, mother and by two sons and daughter. I will also be joining them. The airline must fly direct.\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-sonnet-20240229-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': \"Okay, let's book your travel from Bonn to \"\n",
      "                                  'Amsterdam for 5 people with a direct '\n",
      "                                  'flight:'},\n",
      "                         {'toolUse': {'input': {'departure': 'Bonn',\n",
      "                                                'destination': 'Amsterdam',\n",
      "                                                'number_people': '5',\n",
      "                                                'travel_mode': 'Flight '\n",
      "                                                               '(direct)'},\n",
      "                                      'name': 'book_travel',\n",
      "                                      'toolUseId': 'tooluse_X1U6Kj37Q1GRtFMgrqwKpw'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: anthropic.claude-3-haiku-20240307-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': \"Okay, let's book that trip for you and your \"\n",
      "                                  'family from Bonn to Amsterdam with a direct '\n",
      "                                  'flight:'},\n",
      "                         {'toolUse': {'input': {'departure': 'Bonn',\n",
      "                                                'destination': 'Amsterdam',\n",
      "                                                'number_people': '6',\n",
      "                                                'travel_mode': 'flight'},\n",
      "                                      'name': 'book_travel',\n",
      "                                      'toolUseId': 'tooluse_k5R7rRm2T_eUHVxhjcytzg'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: mistral.mistral-large-2402-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'toolUse': {'input': {'departure': 'Bonn',\n",
      "                                                'destination': 'Amsterdam',\n",
      "                                                'number_people': '6',\n",
      "                                                'travel_mode': 'airline'},\n",
      "                                      'name': 'book_travel',\n",
      "                                      'toolUseId': 'tooluse_jLqCPO0mSPisFG_1190Qlg'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-plus-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will book travel for the user, using the '\n",
      "                                  'information they have provided.'},\n",
      "                         {'toolUse': {'input': {'departure': {'city': 'Bonn'},\n",
      "                                                'destination': {'city': 'Amsterdam'},\n",
      "                                                'number_people': 6,\n",
      "                                                'travel_mode': {'type': 'air'}},\n",
      "                                      'name': 'book_travel',\n",
      "                                      'toolUseId': 'tooluse_ut4IpaMrRq-6fU05dEvI_Q'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n",
      "======== Performing function calling with model: cohere.command-r-v1:0 ========\n",
      "\n",
      "{'message': {'content': [{'text': 'I will use the book_travel function to find '\n",
      "                                  'out the availability and pricing of a '\n",
      "                                  'direct flight from Bonn to Amsterdam for a '\n",
      "                                  'group of seven people.'},\n",
      "                         {'toolUse': {'input': {'departure': {'location': 'Bonn'},\n",
      "                                                'destination': {'location': 'Amsterdam'},\n",
      "                                                'number_people': {'adult': 5,\n",
      "                                                                  'child': 2},\n",
      "                                                'travel_mode': {'airline': 'direct'}},\n",
      "                                      'name': 'book_travel',\n",
      "                                      'toolUseId': 'tooluse_K5nJYh2LTJu-3JStAEfPkA'}}],\n",
      "             'role': 'assistant'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls = [open_ai_meeting_call, open_ai_stock_call, open_ai_travel_call]\n",
    "for call in calls:\n",
    "    print(f\"Example call: {call['messages'][0]['content']}\\n\")\n",
    "    bedrock_call = oai_call_to_bedrock_call(call) \n",
    "\n",
    "    for model_id in MODEL_IDS:\n",
    "        print(f\"======== Performing function calling with model: {model_id} ========\\n\")\n",
    "        output = converse_with_tools(bedrock_call['messages'], \n",
    "                                system=\"you are a helpful assistant.\",\n",
    "                                modelId=model_id,\n",
    "                                toolConfig=bedrock_call['toolConfig'])\n",
    "        pprint.pprint(output['output'])\n",
    "        print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
